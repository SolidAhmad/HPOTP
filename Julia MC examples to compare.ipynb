{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6ff656-2930-47e5-a2d7-f0aae39bcc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A policy graph with 3 nodes.\n",
       " Node indices: 1, 2, 3\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SDDP, HiGHS\n",
    "\n",
    "model = SDDP.LinearPolicyGraph(;\n",
    "    stages = 3,\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do subproblem, node\n",
    "    # State variables\n",
    "    @variable(subproblem, 0 <= volume <= 200, SDDP.State, initial_value = 200)\n",
    "    # Control variables\n",
    "    @variables(subproblem, begin\n",
    "        thermal_generation >= 0\n",
    "        hydro_generation >= 0\n",
    "        hydro_spill >= 0\n",
    "    end)\n",
    "    # Random variables\n",
    "    @variable(subproblem, inflow)\n",
    "    Ω = [0.0, 50.0, 100.0]\n",
    "    P = [1 / 3, 1 / 3, 1 / 3]\n",
    "    SDDP.parameterize(subproblem, Ω, P) do ω\n",
    "        return JuMP.fix(inflow, ω)\n",
    "    end\n",
    "    # Transition function and constraints\n",
    "    @constraints(\n",
    "        subproblem,\n",
    "        begin\n",
    "            volume.out == volume.in - hydro_generation - hydro_spill + inflow\n",
    "            demand_constraint, hydro_generation + thermal_generation == 150\n",
    "        end\n",
    "    )\n",
    "    # Stage-objective\n",
    "    if node == 1\n",
    "        @stageobjective(subproblem, 50 * thermal_generation)\n",
    "    elseif node == 2\n",
    "        @stageobjective(subproblem, 100 * thermal_generation)\n",
    "    else\n",
    "        @assert node == 3\n",
    "        @stageobjective(subproblem, 150 * thermal_generation)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5907a78-72de-4389-a609-6d3f9a26a27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "         SDDP.jl (c) Oscar Dowson and contributors, 2017-24\n",
      "-------------------------------------------------------------------\n",
      "problem\n",
      "  nodes           : 3\n",
      "  state variables : 1\n",
      "  scenarios       : 2.70000e+01\n",
      "  existing cuts   : false\n",
      "options\n",
      "  solver          : serial mode\n",
      "  risk measure    : SDDP.Expectation()\n",
      "  sampling scheme : SDDP.InSampleMonteCarlo\n",
      "subproblem structure\n",
      "  VariableRef                             : [7, 7]\n",
      "  AffExpr in MOI.EqualTo{Float64}         : [2, 2]\n",
      "  VariableRef in MOI.GreaterThan{Float64} : [5, 5]\n",
      "  VariableRef in MOI.LessThan{Float64}    : [1, 2]\n",
      "numerical stability report\n",
      "  matrix range     [1e+00, 1e+00]\n",
      "  objective range  [1e+00, 2e+02]\n",
      "  bounds range     [2e+02, 2e+02]\n",
      "  rhs range        [2e+02, 2e+02]\n",
      "-------------------------------------------------------------------\n",
      " iteration    simulation      bound        time (s)     solves  pid\n",
      "-------------------------------------------------------------------\n",
      "         1   1.250000e+04  3.437500e+03  7.461883e+00        12   1\n",
      "         5   1.000000e+04  8.333333e+03  7.768542e+00        60   1\n",
      "-------------------------------------------------------------------\n",
      "status         : iteration_limit\n",
      "total time (s) : 7.768542e+00\n",
      "total solves   : 60\n",
      "best bound     :  8.333333e+03\n",
      "simulation ci  :  1.156250e+04 ± 2.937447e+03\n",
      "numeric issues : 0\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SDDP.train(model; iteration_limit = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74ec4a7-cda8-461e-b653-3ff5d8dc7ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol, Any} with 10 entries:\n",
       "  :volume             => State{Float64}(200.0, 200.0)\n",
       "  :hydro_spill        => 0.0\n",
       "  :bellman_term       => 3333.33\n",
       "  :noise_term         => 100.0\n",
       "  :node_index         => 1\n",
       "  :stage_objective    => 2500.0\n",
       "  :objective_state    => nothing\n",
       "  :thermal_generation => 50.0\n",
       "  :hydro_generation   => 100.0\n",
       "  :belief             => Dict(1=>1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulations = SDDP.simulate(\n",
    "    # The trained model to simulate.\n",
    "    model,\n",
    "    # The number of replications.\n",
    "    100,\n",
    "    # A list of names to record the values of.\n",
    "    [:volume, :thermal_generation, :hydro_generation, :hydro_spill],\n",
    ")\n",
    "\n",
    "replication = 1\n",
    "stage = 2\n",
    "simulations[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea78b5c-3e2f-405b-adc5-cc4ba2b76e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{aligned}\n",
       "\\min\\quad & 100 thermal\\_generation + {\\_}_{7}\\\\\n",
       "\\text{Subject to} \\quad & -volume\\_in + volume\\_out + hydro\\_generation + hydro\\_spill - inflow = 0.0\\\\\n",
       " & thermal\\_generation + hydro\\_generation = 150.0\\\\\n",
       " & 150 volume\\_out + {\\_}_{7} \\geq 15000.0\\\\\n",
       " & 50 volume\\_out + {\\_}_{7} \\geq 7500.0\\\\\n",
       " & 100 volume\\_out + {\\_}_{7} \\geq 12500.0\\\\\n",
       " & volume\\_in = 200.0\\\\\n",
       " & inflow = 100.0\\\\\n",
       " & volume\\_out \\geq 0.0\\\\\n",
       " & thermal\\_generation \\geq 0.0\\\\\n",
       " & hydro\\_generation \\geq 0.0\\\\\n",
       " & hydro\\_spill \\geq 0.0\\\\\n",
       " & {\\_}_{7} \\geq 0.0\\\\\n",
       " & volume\\_out \\leq 200.0\\\\\n",
       "\\end{aligned} $$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model[2].subproblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ae3e68-c63b-460c-9cb1-2a3d13e0173c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A policy graph with 5 nodes.\n",
       " Node indices: (1, 1), (2, 1), (2, 2), (3, 1), (3, 2)\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SDDP, HiGHS\n",
    "\n",
    "Ω = [\n",
    "    (inflow = 0.0, fuel_multiplier = 1.5),\n",
    "    (inflow = 50.0, fuel_multiplier = 1.0),\n",
    "    (inflow = 100.0, fuel_multiplier = 0.75),\n",
    "]\n",
    "\n",
    "model = SDDP.MarkovianPolicyGraph(;\n",
    "    transition_matrices = Array{Float64,2}[\n",
    "        [1.0]',\n",
    "        [0.75 0.25],\n",
    "        [0.75 0.25; 0.25 0.75],\n",
    "    ],\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do subproblem, node\n",
    "    # Unpack the stage and Markov index.\n",
    "    t, markov_state = node\n",
    "    # Define the state variable.\n",
    "    @variable(subproblem, 0 <= volume <= 200, SDDP.State, initial_value = 200)\n",
    "    # Define the control variables.\n",
    "    @variables(subproblem, begin\n",
    "        thermal_generation >= 0\n",
    "        hydro_generation >= 0\n",
    "        hydro_spill >= 0\n",
    "        inflow\n",
    "    end)\n",
    "    # Define the constraints\n",
    "    @constraints(\n",
    "        subproblem,\n",
    "        begin\n",
    "            volume.out == volume.in + inflow - hydro_generation - hydro_spill\n",
    "            thermal_generation + hydro_generation == 150.0\n",
    "        end\n",
    "    )\n",
    "    # Note how we can use `markov_state` to dispatch an `if` statement.\n",
    "    probability = if markov_state == 1  # wet climate state\n",
    "        [1 / 6, 1 / 3, 1 / 2]\n",
    "    else  # dry climate state\n",
    "        [1 / 2, 1 / 3, 1 / 6]\n",
    "    end\n",
    "\n",
    "    fuel_cost = [50.0, 100.0, 150.0]\n",
    "    SDDP.parameterize(subproblem, Ω, probability) do ω\n",
    "        JuMP.fix(inflow, ω.inflow)\n",
    "        @stageobjective(\n",
    "            subproblem,\n",
    "            ω.fuel_multiplier * fuel_cost[t] * thermal_generation\n",
    "        )\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b37c6cec-c7a6-4985-99a2-0adb267b2c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "         SDDP.jl (c) Oscar Dowson and contributors, 2017-24\n",
      "-------------------------------------------------------------------\n",
      "problem\n",
      "  nodes           : 5\n",
      "  state variables : 1\n",
      "  scenarios       : 1.08000e+02\n",
      "  existing cuts   : false\n",
      "options\n",
      "  solver          : serial mode\n",
      "  risk measure    : SDDP.Expectation()\n",
      "  sampling scheme : SDDP.InSampleMonteCarlo\n",
      "subproblem structure\n",
      "  VariableRef                             : [7, 7]\n",
      "  AffExpr in MOI.EqualTo{Float64}         : [2, 2]\n",
      "  VariableRef in MOI.GreaterThan{Float64} : [5, 5]\n",
      "  VariableRef in MOI.LessThan{Float64}    : [1, 2]\n",
      "numerical stability report\n",
      "  matrix range     [1e+00, 1e+00]\n",
      "  objective range  [1e+00, 2e+02]\n",
      "  bounds range     [2e+02, 2e+02]\n",
      "  rhs range        [2e+02, 2e+02]\n",
      "-------------------------------------------------------------------\n",
      " iteration    simulation      bound        time (s)     solves  pid\n",
      "-------------------------------------------------------------------\n",
      "         1   2.812500e+04  2.663862e+03  8.230925e-03        18   1\n",
      "        10   1.875000e+03  9.250000e+03  2.150083e-02       180   1\n",
      "-------------------------------------------------------------------\n",
      "status         : iteration_limit\n",
      "total time (s) : 2.150083e-02\n",
      "total solves   : 180\n",
      "best bound     :  9.250000e+03\n",
      "simulation ci  :  9.378925e+03 ± 6.906300e+03\n",
      "numeric issues : 0\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SDDP.train(model, iteration_limit= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316b97bd-6cdd-4864-b5ba-64e1f8d63e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:index, :subproblem, :children, :noise_terms, :parameterize, :states, :stage_objective, :stage_objective_set, :bellman_function, :objective_state, :belief_state, :pre_optimize_hook, :post_optimize_hook, :has_integrality, :optimizer, :ext, :lock)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(typeof(model[(1,1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a4fd7c-e0d4-47df-8fe2-24bfcd24e88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{SDDP.SampledState}:\n",
       " SDDP.SampledState(Dict(:volume => 0.0), nothing, nothing, SDDP.Cut(23177.083333333332, Dict(:volume => -157.8125), nothing, nothing, 1, 157.8125 volume_out + _[7] ≥ 23177.083333333332), 23177.083333333332)\n",
       " SDDP.SampledState(Dict(:volume => 146.86468646864685), nothing, nothing, SDDP.Cut(22604.166666666664, Dict(:volume => -95.05208333333333), nothing, nothing, 2, 95.05208333333333 volume_out + _[7] ≥ 22604.166666666664), 8644.372249724973)\n",
       " SDDP.SampledState(Dict(:volume => 200.0), nothing, nothing, SDDP.Cut(22604.166666666664, Dict(:volume => -95.05208333333333), nothing, nothing, 2, 95.05208333333333 volume_out + _[7] ≥ 22604.166666666664), 3593.75)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(:cut_type, :global_theta, :local_thetas, :risk_set_cuts)\n",
    "\n",
    "#(:theta, :states, :objective_states, :belief_states, :cuts, :sampled_states, :cuts_to_be_deleted, :deletion_minimum)\n",
    "\n",
    "#(:intercept, :coefficients, :obj_y, :belief_y, :non_dominated_count, :constraint_ref)\n",
    "\n",
    "\n",
    "model[(1,1)].bellman_function.global_theta.sampled_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b70e75e7-0384-4ee6-878f-a921892fe44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "         SDDP.jl (c) Oscar Dowson and contributors, 2017-24\n",
      "-------------------------------------------------------------------\n",
      "problem\n",
      "  nodes           : 10\n",
      "  state variables : 4\n",
      "  scenarios       : 2.70000e+01\n",
      "  existing cuts   : false\n",
      "options\n",
      "  solver          : serial mode\n",
      "  risk measure    : SDDP.Expectation()\n",
      "  sampling scheme : SDDP.InSampleMonteCarlo\n",
      "subproblem structure\n",
      "  VariableRef                             : [24, 24]\n",
      "  AffExpr in MOI.EqualTo{Float64}         : [3, 3]\n",
      "  AffExpr in MOI.GreaterThan{Float64}     : [1, 1]\n",
      "  AffExpr in MOI.LessThan{Float64}        : [1, 6]\n",
      "  VariableRef in MOI.GreaterThan{Float64} : [20, 20]\n",
      "  VariableRef in MOI.LessThan{Float64}    : [1, 2]\n",
      "numerical stability report\n",
      "  matrix range     [1e+00, 8e+01]\n",
      "  objective range  [1e+00, 1e+03]\n",
      "  bounds range     [6e+01, 6e+01]\n",
      "  rhs range        [2e+02, 3e+03]\n",
      "-------------------------------------------------------------------\n",
      " iteration    simulation      bound        time (s)     solves  pid\n",
      "-------------------------------------------------------------------\n",
      "         1   8.316000e+03  0.000000e+00  1.086497e-02        14   1\n",
      "         5   2.308500e+03  4.074139e+03  1.783800e-02        70   1\n",
      "-------------------------------------------------------------------\n",
      "status         : iteration_limit\n",
      "total time (s) : 1.783800e-02\n",
      "total solves   : 70\n",
      "best bound     :  4.074139e+03\n",
      "simulation ci  :  5.683840e+03 ± 2.365398e+03\n",
      "numeric issues : 0\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "using SDDP, HiGHS, Test\n",
    "\n",
    "S = [  # cutting, stage\n",
    "    0 1 2\n",
    "    0 0 1\n",
    "    0 0 0\n",
    "]\n",
    "t = [60, 60, 245]  # days in period\n",
    "D = [210, 210, 858]  # demand\n",
    "q = [  # selling price per bale\n",
    "    [4.5 4.5 4.5; 4.5 4.5 4.5; 4.5 4.5 4.5],\n",
    "    [5.5 5.5 5.5; 5.5 5.5 5.5; 5.5 5.5 5.5],\n",
    "    [6.5 6.5 6.5; 6.5 6.5 6.5; 6.5 6.5 6.5],\n",
    "]\n",
    "b = [  # predicted yield (bales/acres) from cutting i in weather j.\n",
    "    30 75 37.5\n",
    "    15 37.5 18.25\n",
    "    7.5 18.75 9.325\n",
    "]\n",
    "w = 3000  # max storage\n",
    "C = [50 50 50; 50 50 50; 50 50 50]  # cost to grow hay\n",
    "r = [  # Cost per bale of hay from cutting i during weather condition j.\n",
    "    [5 5 5; 5 5 5; 5 5 5],\n",
    "    [6 6 6; 6 6 6; 6 6 6],\n",
    "    [7 7 7; 7 7 7; 7 7 7],\n",
    "]\n",
    "M = 60.0  # max acreage for planting\n",
    "H = 0.0  # initial inventory\n",
    "V = [0.05, 0.05, 0.05]  # inventory cost\n",
    "L = 3000.0  # max demand for hay\n",
    "\n",
    "graph = SDDP.MarkovianGraph([\n",
    "    ones(Float64, 1, 1),\n",
    "    [0.14 0.69 0.17],\n",
    "    [0.14 0.69 0.17; 0.14 0.69 0.17; 0.14 0.69 0.17],\n",
    "    [0.14 0.69 0.17; 0.14 0.69 0.17; 0.14 0.69 0.17],\n",
    "])\n",
    "\n",
    "model = SDDP.PolicyGraph(\n",
    "    graph;\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do subproblem, index\n",
    "    stage, weather = index\n",
    "    # ===================== State Variables =====================\n",
    "    # Area planted.\n",
    "    @variable(subproblem, 0 <= acres <= M, SDDP.State, initial_value = M)\n",
    "    @variable(\n",
    "        subproblem,\n",
    "        bales[i = 1:3] >= 0,\n",
    "        SDDP.State,\n",
    "        initial_value = (i == 1 ? H : 0)\n",
    "    )\n",
    "    # ===================== Variables =====================\n",
    "    @variables(subproblem, begin\n",
    "        buy[1:3] >= 0  # Quantity of bales to buy from each cutting.\n",
    "        sell[1:3] >= 0 # Quantity of bales to sell from each cutting.\n",
    "        eat[1:3] >= 0  # Quantity of bales to eat from each cutting.\n",
    "        pen_p[1:3] >= 0  # Penalties\n",
    "        pen_n[1:3] >= 0  # Penalties\n",
    "    end)\n",
    "    # ===================== Constraints =====================\n",
    "    if stage == 1\n",
    "        @constraint(subproblem, acres.out <= acres.in)\n",
    "        @constraint(subproblem, [i = 1:3], bales[i].in == bales[i].out)\n",
    "    else\n",
    "        @expression(\n",
    "            subproblem,\n",
    "            cut_ex[c = 1:3],\n",
    "            bales[c].in + buy[c] - eat[c] - sell[c] + pen_p[c] - pen_n[c]\n",
    "        )\n",
    "        @constraints(\n",
    "            subproblem,\n",
    "            begin\n",
    "                # Cannot plant more land than previously cropped.\n",
    "                acres.out <= acres.in\n",
    "                # In each stage we need to meet demand.\n",
    "                sum(eat) >= D[stage-1]\n",
    "                # We can buy and sell other cuttings.\n",
    "                bales[stage-1].out ==\n",
    "                cut_ex[stage-1] + acres.in * b[stage-1, weather]\n",
    "                [c = 1:3; c != stage - 1], bales[c].out == cut_ex[c]\n",
    "                # There is some maximum storage.\n",
    "                sum(bales[i].out for i in 1:3) <= w\n",
    "                # We can only sell what is in storage.\n",
    "                [c = 1:3], sell[c] <= bales[c].in\n",
    "                # Maximum sales quantity.\n",
    "                sum(sell) <= L\n",
    "            end\n",
    "        )\n",
    "    end\n",
    "    # ===================== Stage objective =====================\n",
    "    if stage == 1\n",
    "        @stageobjective(subproblem, 0.0)\n",
    "    else\n",
    "        @stageobjective(\n",
    "            subproblem,\n",
    "            1000 * (sum(pen_p) + sum(pen_n)) +\n",
    "            # cost of growing\n",
    "            C[stage-1, weather] * acres.in +\n",
    "            sum(\n",
    "                # inventory cost\n",
    "                V[stage-1] * bales[cutting].in * t[stage-1] +\n",
    "                # purchase cost\n",
    "                r[cutting][stage-1, weather] * buy[cutting] +\n",
    "                # feed cost\n",
    "                S[cutting, stage-1] * eat[cutting] -\n",
    "                # sell reward\n",
    "                q[cutting][stage-1, weather] * sell[cutting] for\n",
    "                cutting in 1:3\n",
    "            )\n",
    "        )\n",
    "    end\n",
    "    return\n",
    "end\n",
    "SDDP.train(model, iteration_limit = 5)\n",
    "# @test SDDP.termination_status(model) == :simulation_stopping\n",
    "# @test SDDP.calculate_bound(model) ≈ 4074.1391 atol = 1e-5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f8369d9c-53fe-41e3-8eda-b12f3c2eb85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{aligned}\n",
       "\\min\\quad & 1000 pen\\_p_{1} + 1000 pen\\_p_{2} + 1000 pen\\_p_{3} + 1000 pen\\_n_{1} + 1000 pen\\_n_{2} + 1000 pen\\_n_{3} + 50 acres\\_in + 3 bales[1]\\_in + 5 buy_{1} + eat_{1} - 4.5 sell_{1} + 3 bales[2]\\_in + 6 buy_{2} - 5.5 sell_{2} + 3 bales[3]\\_in + 7 buy_{3} - 6.5 sell_{3} + {\\_}_{24}\\\\\n",
       "\\text{Subject to} \\quad & -37.5 acres\\_in - bales[2]\\_in + bales[2]\\_out - buy_{2} + sell_{2} + eat_{2} - pen\\_p_{2} + pen\\_n_{2} = 0.0\\\\\n",
       " & -bales[1]\\_in + bales[1]\\_out - buy_{1} + sell_{1} + eat_{1} - pen\\_p_{1} + pen\\_n_{1} = 0.0\\\\\n",
       " & -bales[3]\\_in + bales[3]\\_out - buy_{3} + sell_{3} + eat_{3} - pen\\_p_{3} + pen\\_n_{3} = 0.0\\\\\n",
       " & eat_{1} + eat_{2} + eat_{3} \\geq 210.0\\\\\n",
       " & -31.55325 acres\\_out - 6.595 bales[2]\\_out + {\\_}_{24} \\geq 1861.8600000000004\\\\\n",
       " & 59.009249999999994 acres\\_out - 6.25 bales[2]\\_out + {\\_}_{24} \\geq 6006.0\\\\\n",
       " & 59.009249999999994 acres\\_out - 6.25 bales[2]\\_out + {\\_}_{24} \\geq 6006.0\\\\\n",
       " & -acres\\_in + acres\\_out \\leq 0.0\\\\\n",
       " & bales[1]\\_out + bales[2]\\_out + bales[3]\\_out \\leq 3000.0\\\\\n",
       " & -bales[1]\\_in + sell_{1} \\leq 0.0\\\\\n",
       " & -bales[2]\\_in + sell_{2} \\leq 0.0\\\\\n",
       " & -bales[3]\\_in + sell_{3} \\leq 0.0\\\\\n",
       " & sell_{1} + sell_{2} + sell_{3} \\leq 3000.0\\\\\n",
       " & acres\\_in = 42.799999999999976\\\\\n",
       " & bales[1]\\_in = 3000.0\\\\\n",
       " & bales[2]\\_in = 0.0\\\\\n",
       " & bales[3]\\_in = 0.0\\\\\n",
       " & acres\\_out \\geq 0.0\\\\\n",
       " & bales[1]\\_out \\geq 0.0\\\\\n",
       " & bales[2]\\_out \\geq 0.0\\\\\n",
       " & bales[3]\\_out \\geq 0.0\\\\\n",
       " & buy_{1} \\geq 0.0\\\\\n",
       " & buy_{2} \\geq 0.0\\\\\n",
       " & buy_{3} \\geq 0.0\\\\\n",
       " & sell_{1} \\geq 0.0\\\\\n",
       " & sell_{2} \\geq 0.0\\\\\n",
       " & sell_{3} \\geq 0.0\\\\\n",
       " & eat_{1} \\geq 0.0\\\\\n",
       " & eat_{2} \\geq 0.0\\\\\n",
       " & eat_{3} \\geq 0.0\\\\\n",
       " & pen\\_p_{1} \\geq 0.0\\\\\n",
       " & pen\\_p_{2} \\geq 0.0\\\\\n",
       " & pen\\_p_{3} \\geq 0.0\\\\\n",
       " & pen\\_n_{1} \\geq 0.0\\\\\n",
       " & pen\\_n_{2} \\geq 0.0\\\\\n",
       " & pen\\_n_{3} \\geq 0.0\\\\\n",
       " & {\\_}_{24} \\geq 0.0\\\\\n",
       " & acres\\_out \\leq 60.0\\\\\n",
       "\\end{aligned} $$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model[(3,2)].subproblem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "daa63755-7b4e-42d8-91e0-393685804fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Vector{Dict{Symbol, Any}}}:\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 3000.0), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 1120.4041000000007, :noise_term => nothing, :node_index => (2, 2), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(3000.0, 0.0), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 3), :stage_objective => -2360.000000000002, :objective_state => nothing, :belief => Dict((3, 3) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 0.0, :noise_term => nothing, :node_index => (4, 3), :stage_objective => 5352.230000000001, :objective_state => nothing, :belief => Dict((4, 3) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 1394.9999999999989), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 3527.904100000003, :noise_term => nothing, :node_index => (2, 3), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 3) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(1394.9999999999989, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000025, :noise_term => nothing, :node_index => (3, 2), :stage_objective => 47.5, :objective_state => nothing, :belief => Dict((3, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 0.0, :noise_term => nothing, :node_index => (4, 1), :stage_objective => 5899.0, :objective_state => nothing, :belief => Dict((4, 1) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 1073.999999999999), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4009.404100000002, :noise_term => nothing, :node_index => (2, 1), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 1) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(1073.999999999999, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 3), :stage_objective => 529.0, :objective_state => nothing, :belief => Dict((3, 3) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4.547473508864641e-13, :noise_term => nothing, :node_index => (4, 2), :stage_objective => 2528.5000000000023, :objective_state => nothing, :belief => Dict((4, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 3000.0), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 1120.4041000000007, :noise_term => nothing, :node_index => (2, 2), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(3000.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 2), :stage_objective => -2360.000000000002, :objective_state => nothing, :belief => Dict((3, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4.547473508864641e-13, :noise_term => nothing, :node_index => (4, 2), :stage_objective => 2528.5000000000023, :objective_state => nothing, :belief => Dict((4, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 3000.0), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 1120.4041000000007, :noise_term => nothing, :node_index => (2, 2), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(3000.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 2), :stage_objective => -2360.000000000002, :objective_state => nothing, :belief => Dict((3, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4.547473508864641e-13, :noise_term => nothing, :node_index => (4, 2), :stage_objective => 2528.5000000000023, :objective_state => nothing, :belief => Dict((4, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 3000.0), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 1120.4041000000007, :noise_term => nothing, :node_index => (2, 2), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(3000.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 3), :stage_objective => -2360.000000000002, :objective_state => nothing, :belief => Dict((3, 3) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4.547473508864641e-13, :noise_term => nothing, :node_index => (4, 2), :stage_objective => 2528.5000000000023, :objective_state => nothing, :belief => Dict((4, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 3000.0), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 1120.4041000000007, :noise_term => nothing, :node_index => (2, 2), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(3000.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 2), :stage_objective => -2360.000000000002, :objective_state => nothing, :belief => Dict((3, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4.547473508864641e-13, :noise_term => nothing, :node_index => (4, 2), :stage_objective => 2528.5000000000023, :objective_state => nothing, :belief => Dict((4, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 3000.0), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 1120.4041000000007, :noise_term => nothing, :node_index => (2, 2), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(3000.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 2), :stage_objective => -2360.000000000002, :objective_state => nothing, :belief => Dict((3, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 0.0, :noise_term => nothing, :node_index => (4, 3), :stage_objective => 5352.230000000001, :objective_state => nothing, :belief => Dict((4, 3) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 1073.999999999999), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4009.404100000002, :noise_term => nothing, :node_index => (2, 1), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 1) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(1073.999999999999, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 3), :stage_objective => 529.0, :objective_state => nothing, :belief => Dict((3, 3) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4.547473508864641e-13, :noise_term => nothing, :node_index => (4, 2), :stage_objective => 2528.5000000000023, :objective_state => nothing, :belief => Dict((4, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]\n",
       " [Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0), SDDP.State{Float64}(0.0, -0.0)], :bellman_term => 4074.1391000000003, :noise_term => nothing, :node_index => (1, 1), :stage_objective => 0.0, :objective_state => nothing, :belief => Dict((1, 1) => 1.0), :acres => SDDP.State{Float64}(60.0, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 3000.0), SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 1120.4041000000007, :noise_term => nothing, :node_index => (2, 2), :stage_objective => 2139.9999999999986, :objective_state => nothing, :belief => Dict((2, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(3000.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(0.0, 0.0)], :bellman_term => 3480.4041000000016, :noise_term => nothing, :node_index => (3, 2), :stage_objective => -2360.000000000002, :objective_state => nothing, :belief => Dict((3, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 42.79999999999997)), Dict(:bales => SDDP.State{Float64}[SDDP.State{Float64}(-0.0, 0.0), SDDP.State{Float64}(0.0, 0.0), SDDP.State{Float64}(-0.0, 0.0)], :bellman_term => 4.547473508864641e-13, :noise_term => nothing, :node_index => (4, 2), :stage_objective => 2528.5000000000023, :objective_state => nothing, :belief => Dict((4, 2) => 1.0), :acres => SDDP.State{Float64}(42.79999999999997, 0.0))]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulations = SDDP.simulate(\n",
    "    # The trained model to simulate.\n",
    "    model,\n",
    "    # The number of replications.\n",
    "    10,\n",
    "    # A list of names to record the values of.\n",
    "    [:acres,:bales],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8ddfcd29-ae8a-4c99-bb22-f472414d58f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol, Any} with 8 entries:\n",
       "  :bales           => SDDP.State{Float64}[State{Float64}(-0.0, 1074.0), State{F…\n",
       "  :bellman_term    => 4009.4\n",
       "  :noise_term      => nothing\n",
       "  :node_index      => (2, 1)\n",
       "  :stage_objective => 2140.0\n",
       "  :objective_state => nothing\n",
       "  :belief          => Dict((2, 1)=>1.0)\n",
       "  :acres           => State{Float64}(42.8, 42.8)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replication = 3\n",
    "stage = 2\n",
    "simulations[replication][stage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e47084-b76a-4336-bc11-70117e72a4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
